### gold_usd_twd_åˆ†æ.py
#
### 2025/06/11 - ä¿®æ­£ç‰ˆ + ä¸­æ–‡å­—å‹è¨­å®š + Logistic Regression å¼·åŒ–é æ¸¬æ¨¡å‹

import yfinance as yf
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import os
import platform
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, classification_report
from sklearn.ensemble import RandomForestClassifier

sns.set(style=â€œwhitegridâ€)

âœ… å­—é«”è¨­å®šï¼ˆæ”¯æ´è·¨å¹³å°ä¸­æ–‡ï¼‰

if platform.system() == â€˜Darwinâ€™:
plt.rcParams[â€˜font.familyâ€™] = [â€˜Arial Unicode MSâ€™]
elif platform.system() == â€˜Windowsâ€™:
plt.rcParams[â€˜font.familyâ€™] = [â€˜Microsoft JhengHeiâ€™]
else:
plt.rcParams[â€˜font.familyâ€™] = [â€˜Noto Sans CJK TCâ€™]

plt.rcParams[â€˜axes.unicode_minusâ€™] = False

1. ä¸‹è¼‰é»ƒé‡‘æœŸè²¨èˆ‡ç¾å…ƒ ETF è³‡æ–™

gold = yf.download(â€œGC=Fâ€, start=â€œ2018-01-01â€, end=â€œ2024-12-31â€)
dxy = yf.download(â€œUUPâ€, start=â€œ2018-01-01â€, end=â€œ2024-12-31â€)  # ç”¨ UUP ä»£æ›¿ DX-Y.NYB

if gold.empty or dxy.empty:
raise Exception(â€œâŒ é‡‘åƒ¹æˆ–ç¾å…ƒæŒ‡æ•¸ï¼ˆUUPï¼‰è³‡æ–™ä¸‹è¼‰å¤±æ•—ï¼Œè«‹æª¢æŸ¥ç¶²è·¯æˆ–ä»£ç¢¼æ˜¯å¦æ­£ç¢ºâ€)

2. è¼‰å…¥å°å¹£åŒ¯ç‡è³‡æ–™

usd_twd_path = â€œ./gold/usd_twd.csvâ€
if not os.path.exists(usd_twd_path):
raise FileNotFoundError(fâ€âŒ æ‰¾ä¸åˆ°æª”æ¡ˆï¼š{usd_twd_path}ï¼Œè«‹ç¢ºèªæª”æ¡ˆä½ç½®èˆ‡åç¨±â€)

usd_twd = pd.read_csv(usd_twd_path, parse_dates=[â€œDateâ€])
usd_twd.set_index(â€œDateâ€, inplace=True)

3. åˆä½µè³‡æ–™ï¼ˆä½¿ç”¨ squeeze() ç¢ºä¿ç‚ºä¸€ç¶­ï¼‰

df = pd.DataFrame({
â€œGoldâ€: gold[â€œCloseâ€].squeeze(),
â€œDXYâ€: dxy[â€œCloseâ€].squeeze(),
â€œUSD_TWDâ€: usd_twd[â€œUSD_TWDâ€].squeeze()
}).dropna()

4. è¨ˆç®—å ±é…¬ç‡ï¼ˆç™¾åˆ†æ¯”è®Šå‹•ï¼‰

returns = df.pct_change().dropna()

5. æ•£ä½ˆåœ– + å›æ­¸ç·š

plt.figure(figsize=(8,6))
sns.regplot(x=returns[â€œDXYâ€], y=returns[â€œGoldâ€], line_kws={â€œcolorâ€:â€œredâ€})
plt.title(â€œé»ƒé‡‘å ±é…¬ vs ç¾å…ƒ ETF(UUP) å ±é…¬â€)
plt.xlabel(â€œç¾å…ƒå ±é…¬ç‡ (UUP)â€)
plt.ylabel(â€œé»ƒé‡‘å ±é…¬ç‡â€)
plt.tight_layout()
plt.savefig(â€œscatter_gold_dxy.pngâ€)
plt.show()

6. ç†±åŠ›åœ–ï¼ˆç›¸é—œä¿‚æ•¸ï¼‰

corr_matrix = returns.corr()
plt.figure(figsize=(6,5))
sns.heatmap(corr_matrix, annot=True, cmap=â€œcoolwarmâ€, fmt=â€.2fâ€)
plt.title(â€œå ±é…¬ç‡ç›¸é—œä¿‚æ•¸ç†±åŠ›åœ–â€)
plt.tight_layout()
plt.savefig(â€œcorrelation_heatmap.pngâ€)
plt.show()

7. æ¼²è·Œäº¤å‰è¡¨

bin_returns = returns.copy()
bin_returns[â€œGoldâ€] = (returns[â€œGoldâ€] > 0).astype(int)
bin_returns[â€œDXYâ€] = (returns[â€œDXYâ€] > 0).astype(int)

crosstab = pd.crosstab(bin_returns[â€œDXYâ€], bin_returns[â€œGoldâ€], normalize=â€˜indexâ€™)
crosstab.columns = [â€œGold_Downâ€, â€œGold_Upâ€]
print(â€\nç¾å…ƒä¸Š/ä¸‹æ¼²å°é»ƒé‡‘æ¼²è·Œå½±éŸ¿ï¼šâ€)
print(crosstab)

è¦–è¦ºåŒ–äº¤å‰è¡¨

crosstab.plot(kind=â€œbarâ€, stacked=True, colormap=â€œcoolwarmâ€)
plt.title(â€œåœ¨ç¾å…ƒæ¼²/è·Œä¸‹ï¼Œé»ƒé‡‘æ¼²è·Œæ©Ÿç‡â€)
plt.xlabel(â€œç¾å…ƒæ¼²è·Œ (0=è·Œ, 1=æ¼²)â€)
plt.ylabel(â€œé»ƒé‡‘æ¼²/è·Œæ¯”ä¾‹â€)
plt.tight_layout()
plt.savefig(â€œgold_usd_crosstab.pngâ€)
plt.close()
print(â€œâœ… Step 7.2 è¦–è¦ºåŒ–äº¤å‰è¡¨çµæŸâ€)

8. é æ¸¬æ¨¡å‹ï¼šLogistic Regression å¼·åŒ–ç‰ˆ

print(â€œâœ… Step 8 é æ¸¬æ¨¡å‹é–‹å§‹â€)
returns[â€˜Gold_Up_Tomorrowâ€™] = (returns[â€˜Goldâ€™].shift(-1) > 0).astype(int)
returns[â€˜Gold_Lag1â€™] = returns[â€˜Goldâ€™].shift(1)
returns[â€˜DXY_Lag1â€™] = returns[â€˜DXYâ€™].shift(1)
returns.dropna(inplace=True)

X = returns[[â€˜DXYâ€™, â€˜USD_TWDâ€™, â€˜Gold_Lag1â€™, â€˜DXY_Lag1â€™]]
y = returns[â€˜Gold_Up_Tomorrowâ€™]

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

model = LogisticRegression(class_weight=â€˜balancedâ€™)
model.fit(X_train, y_train)
y_pred = model.predict(X_test)

print(â€\nğŸ¯ Logistic Regression æ¨¡å‹é æ¸¬çµæœâ€)
print(â€œæº–ç¢ºç‡ï¼šâ€, accuracy_score(y_test, y_pred))
print(classification_report(y_test, y_pred))

coef_df = pd.DataFrame({
â€˜Featureâ€™: X.columns,
â€˜Coefficientâ€™: model.coef_[0]
})
print(â€\nç‰¹å¾µå½±éŸ¿ä¿‚æ•¸ï¼šâ€)
print(coef_df)

âœ… é¡å¤–ï¼šRandom Forest é æ¸¬æ¯”è¼ƒ

forest = RandomForestClassifier(random_state=42)
forest.fit(X_train, y_train)
y_pred_rf = forest.predict(X_test)

print(â€\nğŸŒ² Random Forest æ¨¡å‹é æ¸¬çµæœâ€)
print(â€œæº–ç¢ºç‡ï¼šâ€, accuracy_score(y_test, y_pred_rf))
print(classification_report(y_test, y_pred_rf))

feature_importances = pd.DataFrame({
â€˜Featureâ€™: X.columns,
â€˜Importanceâ€™: forest.feature_importances_
}).sort_values(by=â€œImportanceâ€, ascending=False)
print(â€\nç‰¹å¾µé‡è¦æ€§ (Random Forest)ï¼šâ€)
print(feature_importances)
print(â€œâœ… æ‰€æœ‰é æ¸¬åˆ†æçµæŸâ€)